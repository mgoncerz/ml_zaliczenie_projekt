{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projekt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPH2iL1RIQ/uqVVRUj6g7/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgoncerz/ml_zaliczenie_projekt/blob/master/projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPF1vvSAi4-7",
        "colab_type": "text"
      },
      "source": [
        "The idea is to compare the accuracy of various ML methods in reckognizing handwritten letters from alphabets of different complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrRNlb75k5Uz",
        "colab_type": "text"
      },
      "source": [
        "Loading libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYvfn_JJk7WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop, adam\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from IPython.display import Image \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHWPbN2ukjhn",
        "colab_type": "text"
      },
      "source": [
        "Hiragana:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWKP8tdPknnR",
        "colab_type": "text"
      },
      "source": [
        "1. Loading data (https://www.kaggle.com/anokas/kuzushiji):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925tFUn1kiIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_train = np.load('kmnist-train-imgs.npz')['arr_0']\n",
        "images_test = np.load('kmnist-test-imgs.npz')['arr_0']\n",
        "\n",
        "data_length = images_train[0].shape[0] * images_train[0].shape[1]\n",
        "\n",
        "x_train = images_train.reshape(len(images_train), data_length).astype('float32')\n",
        "x_test = images_test.reshape(len(images_test), data_length).astype('float32')\n",
        "\n",
        "labels_train = np.load('kmnist-train-labels.npz')['arr_0']\n",
        "labels_test = np.load('kmnist-test-labels.npz')['arr_0']\n",
        "\n",
        "labels_map = pd.read_csv(\"kmnist_classmap.csv\", encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWJkRGZ7lEv7",
        "colab_type": "text"
      },
      "source": [
        "2. Input data analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgrTXOKElISo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(labels_map)\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "for i in range(100):\n",
        "  ax = fig.add_subplot(10,10,i+1,xticks=[], yticks=[])\n",
        "  ax.imshow(images_train[i], cmap=plt.cm.binary, interpolation='nearest')\n",
        "  ax.text(1, 4, str(labels_train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ1Jxg66t1Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "projection = PCA(n_components=2).fit_transform(x_train)\n",
        "plt.scatter(projection[:, 0], projection[:, 1], c=labels_train.astype(int), cmap=plt.get_cmap('Paired', 10), vmin=-0.5, vmax=9.5)\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnQIXtNYlpeo",
        "colab_type": "text"
      },
      "source": [
        "3. Simple approach (Fisher):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-SvaWxX0Se_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Fisher:\")\n",
        "f_model = LinearDiscriminantAnalysis()\n",
        "f_model.fit(x_train, labels_train) #note this takes labels as single numbers per input element, not transformed to dij form\n",
        "f_prediction = f_model.predict(x_test)\n",
        "\n",
        "print(\"Score: \", f_model.score(x_test, labels_test))\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "print(metrics.classification_report(labels_test, f_prediction))\n",
        "\n",
        "f_cfm = metrics.plot_confusion_matrix(f_model, x_test, labels_test, cmap=plt.cm.Blues, normalize = \"true\", ax = axes)\n",
        "f_cfm.ax_.set_title(\"Fisher confusion matrix\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txrhPbmKEgz_",
        "colab_type": "text"
      },
      "source": [
        "4. k-neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aMuBVwsEjP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"k-neighbors:\")\n",
        "kneighbors_model = KNeighborsClassifier(3)\n",
        "kneighbors_model.fit(x_train, labels_train) #note this takes labels as single numbers per input element, not transformed to dij form\n",
        "kneighbors_prediction = kneighbors_model.predict(x_test)\n",
        "\n",
        "print(\"Score: \", kneighbors_model.score(x_test, labels_test))\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "print(metrics.classification_report(labels_test, kneighbors_prediction))\n",
        "\n",
        "f_cfm = metrics.plot_confusion_matrix(kneighbors_model, x_test, labels_test, cmap=plt.cm.Blues, normalize = \"true\", ax = axes)\n",
        "f_cfm.ax_.set_title(\"k-neighbors confusion matrix\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdFa3n3SsmT8",
        "colab_type": "text"
      },
      "source": [
        "5. Boosted Decision Trees (AdaBoost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95yApAd0uUgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"AdaBoost:\")\n",
        "\n",
        "adaboost_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=60),n_estimators=10)\n",
        "\n",
        "adaboost_model.fit(x_train, labels_train) #note this takes labels as single numbers per input element, not transformed to dij form\n",
        "adaboost_prediction = adaboost_model.predict(x_test)\n",
        "\n",
        "print(\"Score: \", adaboost_model.score(x_test, labels_test))\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "print(metrics.classification_report(labels_test, adaboost_prediction))\n",
        "\n",
        "adaboost_cfm = metrics.plot_confusion_matrix(adaboost_model, x_test, labels_test, cmap=plt.cm.Blues, normalize = \"true\", ax = axes)\n",
        "adaboost_cfm.ax_.set_title(\"AdaBoost confusion matrix\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSKfxpMnD5Tq",
        "colab_type": "text"
      },
      "source": [
        "6. Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXifOVFZEXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_normalized = x_train / 255\n",
        "x_test_normalized = x_test / 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(labels_train, 10)\n",
        "y_test = keras.utils.to_categorical(labels_test, 10)\n",
        "\n",
        "snn_model = Sequential()\n",
        "snn_model.add(Dense(data_length, activation='relu', input_shape=(data_length,)))\n",
        "snn_model.add(Dropout(0.2))\n",
        "snn_model.add(Dense(data_length, activation='relu'))\n",
        "snn_model.add(Dropout(0.2))\n",
        "snn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "snn_model.summary()\n",
        "\n",
        "snn_model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "\n",
        "n_epochs = 10\n",
        "snn_history = snn_model.fit(x_train_normalized, y_train, batch_size=200, epochs=n_epochs, verbose=True, validation_data=(x_test_normalized, y_test))\n",
        "print(snn_model.evaluate(x_test_normalized, y_test))\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(snn_history.history['acc'], 'r')\n",
        "plt.plot(snn_history.history['val_acc'],'g')\n",
        "plt.xticks(np.arange(0, n_epochs, 10.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Cat_Accuracy vs Validation Cat_Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(snn_history.history['loss'],'r')\n",
        "plt.plot(snn_history.history['val_loss'],'g')\n",
        "plt.xticks(np.arange(0, n_epochs, 10.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w150P8uj7NMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "snn_prediction = snn_model.predict(x_test_normalized)\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "print(metrics.classification_report(labels_test, np.argmax(snn_prediction, axis=1)))\n",
        "\n",
        "snn_cfm = metrics.confusion_matrix(labels_test, np.argmax(snn_prediction, axis=1), normalize='true')\n",
        "snn_cfm_tp = pd.DataFrame(snn_cfm, range(10),range(10))\n",
        "sn.heatmap(snn_cfm_tp, annot=True,annot_kws={\"size\": 12}, cmap=plt.cm.Blues).set_title(\"Simple Neural Network confusion matrix\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW-Doaq-qZzu",
        "colab_type": "text"
      },
      "source": [
        "7. Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TSUIiq04CDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_normalized = x_train / 255\n",
        "x_test_normalized = x_test / 255\n",
        "\n",
        "x_train_normalized = x_train_normalized.reshape(x_train_normalized.shape[0], images_train[0].shape[0], images_train[0].shape[1], 1)\n",
        "x_test_normalized = x_test_normalized.reshape(x_test_normalized.shape[0], images_test[0].shape[0], images_test[0].shape[1], 1)\n",
        "input_shape = (images_train[0].shape[0], images_train[0].shape[1], 1)\n",
        "print(x_train_normalized.shape)\n",
        "print(input_shape)\n",
        "y_train = keras.utils.to_categorical(labels_train, 10)\n",
        "y_test = keras.utils.to_categorical(labels_test, 10)\n",
        "\n",
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Conv2D(64, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer=adam(), metrics=['accuracy'])\n",
        "\n",
        "n_epochs = 20\n",
        "cnn_history = cnn_model.fit(x_train_normalized, y_train, batch_size=1000, epochs=n_epochs, verbose=True, validation_data=(x_test_normalized, y_test))\n",
        "print(cnn_model.evaluate(x_test_normalized, y_test))\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(cnn_history.history['acc'], 'r')\n",
        "plt.plot(cnn_history.history['val_acc'],'g')\n",
        "plt.xticks(np.arange(0, n_epochs, 10.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Cat_Accuracy vs Validation Cat_Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(cnn_history.history['loss'],'r')\n",
        "plt.plot(cnn_history.history['val_loss'],'g')\n",
        "plt.xticks(np.arange(0, n_epochs, 10.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrOCppLKASx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_prediction = cnn_model.predict(x_test_normalized)\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20,20))\n",
        "\n",
        "print(metrics.classification_report(labels_test, np.argmax(cnn_prediction, axis=1)))\n",
        "\n",
        "cnn_cfm = metrics.confusion_matrix(labels_test, np.argmax(cnn_prediction, axis=1), normalize='true')\n",
        "cnn_cfm_tp = pd.DataFrame(cnn_cfm, range(10),range(10))\n",
        "sn.heatmap(cnn_cfm_tp, annot=True,annot_kws={\"size\": 12}, cmap=plt.cm.Blues).set_title(\"Convolutional Neural Network confusion matrix\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}